Training started
Parameter type float32, optimization type float32, casting types false
Allocating memory for Adam-specific shards
Ep. 2.258 : Up. 4 : Sen. 512 : Cost 9.69286919 * 13,547 @ 3,630 after 13,547
Ep. 3.400 : Up. 6 : Sen. 768 : Cost 9.68952084 * 6,851 @ 3,634 after 20,398
Ep. 5.131 : Up. 9 : Sen. 1,152 : Cost 9.68455029 * 10,387 @ 3,526 after 30,785
Ep. 6.793 : Up. 12 : Sen. 1,536 : Cost 9.68291855 * 9,975 @ 3,457 after 40,760
Seen 1,542 samples
Starting data epoch 2 in logical epoch 6.819
Ep. 8.472 : Up. 16 : Sen. 384 : Cost 9.67040443 * 10,074 @ 3,589 after 50,834
Ep. 10.219 : Up. 19 : Sen. 768 : Cost 9.66527557 * 10,481 @ 3,634 after 61,315
Training finished
Saving model to log_epoch_t/model.npz
Saving Adam parameters
