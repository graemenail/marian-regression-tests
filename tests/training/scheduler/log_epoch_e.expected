Training started
Parameter type float32, optimization type float32, casting types false
Allocating memory for Adam-specific shards
Seen 1,542 samples
Starting data epoch 2 in logical epoch 1.000
Ep. 1.000 : Up. 10 : Sen. 768 : Cost 9.68879700 * 61,315 @ 6,851 after 61,315
Seen 1,542 samples
Starting data epoch 3 in logical epoch 1.500
Ep. 1.500 : Up. 20 : Sen. 1,536 : Cost 9.67091274 * 61,279 @ 6,585 after 122,594
Seen 1,542 samples
Starting data epoch 4 in logical epoch 2.000
Seen 1,542 samples
Starting data epoch 5 in logical epoch 2.500
Ep. 2.500 : Up. 30 : Sen. 512 : Cost 9.65089798 * 54,621 @ 7,219 after 177,215
Seen 1,542 samples
Starting data epoch 6 in logical epoch 3.000
Ep. 3.000 : Up. 40 : Sen. 1,280 : Cost 9.63199615 * 61,545 @ 6,916 after 238,760
Seen 1,542 samples
Starting data epoch 7 in logical epoch 3.500
Training finished
Saving model to log_epoch_e/model.npz
Saving Adam parameters
